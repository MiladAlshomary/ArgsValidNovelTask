{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "915e68f6-6e4c-461e-a10a-a13836dc7bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbd4e5da-beef-4f0d-90ee-ca4a517d5d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"../../data-ceph/arguana/argmining22-sharedtask/models/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894e8128-0b5f-499e-8a0a-2461877da390",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Prepare the files for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "131f4fd4-dc90-4df4-b509-d687120bc4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "taska_training_df = pd.read_csv('../data/TaskA_train.csv')\n",
    "taska_valid_df = pd.read_csv('../data/TaskA_dev.csv')\n",
    "\n",
    "taska_training_df.insert(loc=0,column='row_num',value=np.arange(len(taska_training_df)))\n",
    "taska_valid_df.insert(loc=0,column='row_num',value=np.arange(len(taska_valid_df)))\n",
    "\n",
    "# taska_training_df['input_txt'] = taska_training_df.apply(lambda x: '[CLS] {}:{} [SEP] {} [SEP]'.format(x['topic'], x['Premise'], x['Conclusion']), axis=1)\n",
    "# taska_valid_df['input_txt'] = taska_valid_df.apply(lambda x: '[CLS] {}:{} [SEP] {} [SEP]'.format(x['topic'], x['Premise'], x['Conclusion']), axis=1)\n",
    "taska_training_df['input_txt'] = taska_training_df.apply(lambda x: '{}:{}  </s></s> {} '.format(x['topic'], x['Premise'], x['Conclusion']), axis=1)\n",
    "taska_valid_df['input_txt'] = taska_valid_df.apply(lambda x: '{}:{} </s></s> {}'.format(x['topic'], x['Premise'], x['Conclusion']), axis=1)\n",
    "\n",
    "\n",
    "taska_training_df['Premise'] = taska_training_df.apply(lambda x: x['topic'] + ' : ' +  x['Premise'], axis=1)\n",
    "taska_valid_df['Premise'] = taska_valid_df.apply(lambda x: x['topic'] + ' : ' +  x['Premise'], axis=1)\n",
    "\n",
    "taska_validity_train_df = taska_training_df[taska_training_df.Validity != 0].copy()\n",
    "taska_validity_valid_df = taska_valid_df[taska_valid_df.Validity != 0].copy()\n",
    "\n",
    "taska_validity_train_df['label'] = taska_validity_train_df.Validity.apply(lambda x : 1 if x == 1 else 0)\n",
    "taska_validity_valid_df['label'] = taska_validity_valid_df.Validity.apply(lambda x : 1 if x == 1 else 0)\n",
    "\n",
    "taska_novelty_train_df = taska_training_df[taska_training_df.Novelty != 0].copy()\n",
    "taska_novelty_valid_df = taska_valid_df[taska_valid_df.Novelty != 0].copy()\n",
    "\n",
    "taska_novelty_train_df['label'] = taska_novelty_train_df.Novelty.apply(lambda x : 1 if x == 1 else 0)\n",
    "taska_novelty_valid_df['label'] = taska_novelty_valid_df.Novelty.apply(lambda x : 1 if x == 1 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5fb17cb-22a2-4c82-96fa-045baebc82c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "taska_validity_train_df[['row_num',  'label', 'input_txt']].to_csv('../data/multitask_data/validity_training_df.tsv', sep='\\t', header=False, index=False)\n",
    "taska_validity_valid_df[['row_num', 'label', 'input_txt' ]].to_csv('../data/multitask_data/validity_valid_df.tsv', sep='\\t', header=False, index=False)\n",
    "\n",
    "taska_novelty_train_df[['row_num', 'label', 'input_txt']].to_csv('../data/multitask_data/novelty_training_df.tsv', sep='\\t', header=False, index=False)\n",
    "taska_novelty_valid_df[['row_num', 'label', 'input_txt']].to_csv('../data/multitask_data/novelty_valid_df.tsv', sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e92647-7dfa-40df-9bfe-19666bc989a4",
   "metadata": {},
   "source": [
    "### Train BERT model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76b5e120-f457-4e80-acb8-d6e1b579fd93",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task object created from task file...\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /mnt/ceph/storage/data-tmp/current//sile2804/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /mnt/ceph/storage/data-tmp/current//sile2804/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current//sile2804/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "bert model tokenizer loaded for config bert-base-uncased\n",
      "Loading raw data for task TaskA from ../data/multitask_data/novelty_training_df.tsv\n",
      "Processing Started...\n",
      "Data Size:  718\n",
      "number of threads:  1\n",
      "100%|████████████████████████████████████████| 718/718 [00:00<00:00, 822.20it/s]\n",
      "Data Processing done for TaskA. File saved at ../data/multitask_data/bert-base-uncased_prepared_data/novelty_training_df.json\n",
      "Loading raw data for task TaskA from ../data/multitask_data/novelty_valid_df.tsv\n",
      "Processing Started...\n",
      "Data Size:  200\n",
      "number of threads:  1\n",
      "100%|████████████████████████████████████████| 200/200 [00:00<00:00, 651.58it/s]\n",
      "Data Processing done for TaskA. File saved at ../data/multitask_data/bert-base-uncased_prepared_data/novelty_valid_df.json\n",
      "Loading raw data for task TaskB from ../data/multitask_data/validity_training_df.tsv\n",
      "Processing Started...\n",
      "Data Size:  721\n",
      "number of threads:  1\n",
      "100%|████████████████████████████████████████| 721/721 [00:00<00:00, 815.57it/s]\n",
      "Data Processing done for TaskB. File saved at ../data/multitask_data/bert-base-uncased_prepared_data/validity_training_df.json\n",
      "Loading raw data for task TaskB from ../data/multitask_data/validity_valid_df.tsv\n",
      "Processing Started...\n",
      "Data Size:  199\n",
      "number of threads:  1\n",
      "100%|████████████████████████████████████████| 199/199 [00:00<00:00, 657.89it/s]\n",
      "Data Processing done for TaskB. File saved at ../data/multitask_data/bert-base-uncased_prepared_data/validity_valid_df.json\n"
     ]
    }
   ],
   "source": [
    "! python ../../multi-task-NLP/data_preparation.py \\\n",
    "  --task_file ../data/multitask_data/bert_based_task.yml \\\n",
    "  --data_dir ../data/multitask_data/ \\\n",
    "  --max_seq_len 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "554dc9e2-e688-4815-beef-bcf6d2bb106d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - logger created.\n",
      "INFO - ARGS : {'data_dir': '../data/multitask_data/bert-base-uncased_prepared_data/', 'task_file': '../data/multitask_data/bert_based_task.yml', 'out_dir': '../data/multitask_data/bert_model/', 'epochs': 3, 'freeze_shared_model': False, 'train_batch_size': 8, 'eval_batch_size': 16, 'grad_accumulation_steps': 2, 'num_of_warmup_steps': 0, 'learning_rate': 0.005, 'epsilon': 1e-08, 'grad_clip_value': 1.0, 'log_file': 'multi_task_logs.log', 'log_dir': '../data/multitask_data/logs/', 'log_per_updates': 250, 'seed': 42, 'max_seq_len': 512, 'save_per_updates': 0, 'limit_save': 15, 'load_saved_model': None, 'eval_while_train': True, 'test_while_train': False, 'resume_train': False, 'finetune': False, 'debug_mode': False, 'silent': False}\n",
      "INFO - Task params object created from task file...\n",
      "INFO - task parameters:\n",
      " {'TaskA': {'config_name': 'bert-base-uncased', 'dropout_prob': 0.3, 'file_names': ['novelty_training_df.tsv', 'novelty_valid_df.tsv'], 'label_map_or_file': [1, 0], 'loss_type': 'CrossEntropyLoss', 'metrics': ['classification_accuracy', 'classification_f1_score'], 'model_type': 'BERT', 'task_type': 'SingleSenClassification'}, 'TaskB': {'config_name': 'bert-base-uncased', 'file_names': ['validity_training_df.tsv', 'validity_valid_df.tsv'], 'label_map_or_file': [1, 0], 'loss_type': 'CrossEntropyLoss', 'metrics': ['classification_accuracy', 'classification_f1_score'], 'model_type': 'BERT', 'task_type': 'SingleSenClassification'}}\n",
      "INFO - Tensorboard writing at ../data/multitask_data/logs/tb_logs\n",
      "INFO - Creating data handlers for training...\n",
      "INFO - Reading data from file ../data/multitask_data/bert-base-uncased_prepared_data/novelty_training_df.json\n",
      "INFO - Read Data for Task Id: 0 Task Name: TaskA. Samples 718\n",
      "INFO - Reading data from file ../data/multitask_data/bert-base-uncased_prepared_data/validity_training_df.json\n",
      "INFO - Read Data for Task Id: 1 Task Name: TaskB. Samples 721\n",
      "INFO - Creating data handlers for dev...\n",
      "INFO - Reading data from file ../data/multitask_data/bert-base-uncased_prepared_data/novelty_valid_df.json\n",
      "INFO - Read Data for Task Id: 0 Task Name: TaskA. Samples 200\n",
      "INFO - Reading data from file ../data/multitask_data/bert-base-uncased_prepared_data/validity_valid_df.json\n",
      "INFO - Read Data for Task Id: 1 Task Name: TaskB. Samples 199\n",
      "INFO - NUM TRAIN STEPS: 270\n",
      "INFO - len of dataloader: 1439\n",
      "INFO - Making multi-task model...\n",
      "INFO - Using number of gpus: 2\n",
      "INFO - Making shared model from given config name bert-base-uncased\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current//sile2804/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /mnt/ceph/storage/data-tmp/current//sile2804/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "INFO - \n",
      "####################### EPOCH 0 ###################\n",
      "\n",
      "Epoch: 0:   0%|                                         | 0/180 [00:00<?, ?it/s]INFO - Steps: 0 Task: TaskB Avg.Loss: 0.6412963271141052 Task Loss: 0.6412963271141052\n",
      "Epoch: 0: 181it [00:30, 16.41it/s]                                              INFO - model saved in 90 global step at ../data/multitask_data/bert_model/multi_task_model_0_90.pt\n",
      "INFO - \n",
      "Running Evaluation on dev...\n",
      "\n",
      "Eval:   0%|                                              | 0/25 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1944: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "\n",
      "Eval:  12%|████▌                                 | 3/25 [00:00<00:00, 28.12it/s]\u001b[A\n",
      "Eval:  24%|█████████                             | 6/25 [00:00<00:00, 29.10it/s]\u001b[A\n",
      "Eval:  40%|██████████████▊                      | 10/25 [00:00<00:00, 31.62it/s]\u001b[A\n",
      "Eval:  56%|████████████████████▋                | 14/25 [00:00<00:00, 31.67it/s]\u001b[A\n",
      "Eval:  72%|██████████████████████████▋          | 18/25 [00:00<00:00, 31.88it/s]\u001b[A\n",
      "Eval:  88%|████████████████████████████████▌    | 22/25 [00:00<00:00, 22.59it/s]\u001b[A\n",
      "Eval: 26it [00:00, 26.74it/s]                                                   \u001b[A\n",
      "INFO - ********** TaskA Evaluation************\n",
      "\n",
      "INFO - classification_accuracy : 59.0\n",
      "INFO - classification_f1_score : 0.37106918238993714\n",
      "INFO - ********** TaskB Evaluation************\n",
      "\n",
      "INFO - classification_accuracy : 62.8140703517588\n",
      "INFO - classification_f1_score : 0.3858024691358025\n",
      "Epoch: 0: 181it [00:53,  3.37it/s]\n",
      "INFO - \n",
      "####################### EPOCH 1 ###################\n",
      "\n",
      "\n",
      "Epoch: 1:   0%|                                         | 0/180 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch: 1:   1%|▎                                | 2/180 [00:00<00:11, 15.82it/s]\u001b[A\n",
      "Epoch: 1:   2%|▋                                | 4/180 [00:00<00:11, 15.41it/s]\u001b[A\n",
      "Epoch: 1:   3%|█                                | 6/180 [00:00<00:10, 16.07it/s]\u001b[A\n",
      "Epoch: 1:   4%|█▍                               | 8/180 [00:00<00:10, 16.19it/s]\u001b[A\n",
      "Epoch: 1:   6%|█▊                              | 10/180 [00:00<00:10, 15.81it/s]\u001b[A\n",
      "Epoch: 1:   7%|██▏                             | 12/180 [00:00<00:10, 15.96it/s]\u001b[A\n",
      "Epoch: 1:   8%|██▍                             | 14/180 [00:00<00:10, 16.10it/s]\u001b[A\n",
      "Epoch: 1:   9%|██▊                             | 16/180 [00:01<00:10, 15.93it/s]\u001b[A\n",
      "Epoch: 1:  10%|███▏                            | 18/180 [00:01<00:10, 16.05it/s]\u001b[A\n",
      "Epoch: 1:  11%|███▌                            | 20/180 [00:01<00:10, 15.79it/s]\u001b[A\n",
      "Epoch: 1:  12%|███▉                            | 22/180 [00:01<00:09, 15.84it/s]\u001b[A\n",
      "Epoch: 1:  13%|████▎                           | 24/180 [00:01<00:09, 15.91it/s]\u001b[A\n",
      "Epoch: 1:  14%|████▌                           | 26/180 [00:01<00:09, 15.83it/s]\u001b[A\n",
      "Epoch: 1:  16%|████▉                           | 28/180 [00:01<00:09, 15.92it/s]\u001b[A\n",
      "Epoch: 1:  17%|█████▎                          | 30/180 [00:01<00:09, 15.78it/s]\u001b[A\n",
      "Epoch: 1:  18%|█████▋                          | 32/180 [00:02<00:09, 15.87it/s]\u001b[A\n",
      "Epoch: 1:  19%|██████                          | 34/180 [00:02<00:09, 15.96it/s]\u001b[A\n",
      "Epoch: 1:  20%|██████▍                         | 36/180 [00:02<00:09, 15.98it/s]\u001b[A\n",
      "Epoch: 1:  21%|██████▊                         | 38/180 [00:02<00:08, 16.06it/s]\u001b[A\n",
      "Epoch: 1:  22%|███████                         | 40/180 [00:02<00:08, 15.89it/s]\u001b[A\n",
      "Epoch: 1:  23%|███████▍                        | 42/180 [00:02<00:08, 15.68it/s]\u001b[A\n",
      "Epoch: 1:  24%|███████▊                        | 44/180 [00:02<00:08, 15.65it/s]\u001b[A\n",
      "Epoch: 1:  26%|████████▏                       | 46/180 [00:02<00:08, 15.50it/s]\u001b[A\n",
      "Epoch: 1:  27%|████████▌                       | 48/180 [00:03<00:08, 15.52it/s]\u001b[A\n",
      "Epoch: 1:  28%|████████▉                       | 50/180 [00:03<00:08, 15.52it/s]\u001b[A\n",
      "Epoch: 1:  29%|█████████▏                      | 52/180 [00:03<00:08, 15.30it/s]\u001b[A\n",
      "Epoch: 1:  30%|█████████▌                      | 54/180 [00:03<00:08, 15.59it/s]\u001b[A\n",
      "Epoch: 1:  31%|█████████▉                      | 56/180 [00:03<00:07, 15.55it/s]\u001b[A\n",
      "Epoch: 1:  32%|██████████▎                     | 58/180 [00:03<00:07, 15.87it/s]\u001b[A\n",
      "Epoch: 1:  33%|██████████▋                     | 60/180 [00:03<00:07, 15.89it/s]\u001b[A\n",
      "Epoch: 1:  34%|███████████                     | 62/180 [00:03<00:07, 15.85it/s]\u001b[A\n",
      "Epoch: 1:  36%|███████████▍                    | 64/180 [00:04<00:07, 15.86it/s]\u001b[A\n",
      "Epoch: 1:  37%|███████████▋                    | 66/180 [00:04<00:07, 15.84it/s]\u001b[A\n",
      "Epoch: 1:  38%|████████████                    | 68/180 [00:04<00:07, 15.85it/s]\u001b[A\n",
      "Epoch: 1:  39%|████████████▍                   | 70/180 [00:04<00:06, 16.02it/s]\u001b[A\n",
      "Epoch: 1:  40%|████████████▊                   | 72/180 [00:04<00:06, 15.66it/s]\u001b[A\n",
      "Epoch: 1:  41%|█████████████▏                  | 74/180 [00:04<00:06, 15.80it/s]\u001b[A\n",
      "Epoch: 1:  42%|█████████████▌                  | 76/180 [00:04<00:06, 15.79it/s]\u001b[A\n",
      "Epoch: 1:  43%|█████████████▊                  | 78/180 [00:04<00:06, 15.76it/s]\u001b[A\n",
      "Epoch: 1:  44%|██████████████▏                 | 80/180 [00:05<00:06, 15.94it/s]\u001b[A\n",
      "Epoch: 1:  46%|██████████████▌                 | 82/180 [00:05<00:06, 15.83it/s]\u001b[A\n",
      "Epoch: 1:  47%|██████████████▉                 | 84/180 [00:05<00:06, 15.82it/s]\u001b[A\n",
      "Epoch: 1:  48%|███████████████▎                | 86/180 [00:05<00:05, 15.78it/s]\u001b[A\n",
      "Epoch: 1:  49%|███████████████▋                | 88/180 [00:05<00:05, 16.14it/s]\u001b[A\n",
      "Epoch: 1:  50%|████████████████                | 90/180 [00:05<00:05, 15.92it/s]\u001b[A\n",
      "Epoch: 1:  51%|████████████████▎               | 92/180 [00:05<00:05, 15.82it/s]\u001b[A\n",
      "Epoch: 1:  52%|████████████████▋               | 94/180 [00:05<00:05, 15.82it/s]\u001b[A\n",
      "Epoch: 1:  53%|█████████████████               | 96/180 [00:06<00:05, 15.82it/s]\u001b[A\n",
      "Epoch: 1:  54%|█████████████████▍              | 98/180 [00:06<00:05, 15.59it/s]\u001b[A\n",
      "Epoch: 1:  56%|█████████████████▏             | 100/180 [00:06<00:05, 15.48it/s]\u001b[A\n",
      "Epoch: 1:  57%|█████████████████▌             | 102/180 [00:06<00:04, 15.90it/s]\u001b[A\n",
      "Epoch: 1:  58%|█████████████████▉             | 104/180 [00:06<00:04, 15.87it/s]\u001b[A\n",
      "Epoch: 1:  59%|██████████████████▎            | 106/180 [00:06<00:04, 15.80it/s]\u001b[A\n",
      "Epoch: 1:  60%|██████████████████▌            | 108/180 [00:06<00:04, 15.78it/s]\u001b[A\n",
      "Epoch: 1:  61%|██████████████████▉            | 110/180 [00:06<00:04, 15.85it/s]\u001b[A\n",
      "Epoch: 1:  62%|███████████████████▎           | 112/180 [00:07<00:04, 15.85it/s]\u001b[A\n",
      "Epoch: 1:  63%|███████████████████▋           | 114/180 [00:07<00:04, 16.01it/s]\u001b[A\n",
      "Epoch: 1:  64%|███████████████████▉           | 116/180 [00:07<00:03, 16.12it/s]\u001b[A\n",
      "Epoch: 1:  66%|████████████████████▎          | 118/180 [00:07<00:03, 16.00it/s]\u001b[A\n",
      "Epoch: 1:  67%|████████████████████▋          | 120/180 [00:07<00:03, 15.92it/s]\u001b[A\n",
      "Epoch: 1:  68%|█████████████████████          | 122/180 [00:07<00:03, 16.07it/s]\u001b[A\n",
      "Epoch: 1:  69%|█████████████████████▎         | 124/180 [00:07<00:03, 16.19it/s]\u001b[A\n",
      "Epoch: 1:  70%|█████████████████████▋         | 126/180 [00:07<00:03, 16.12it/s]\u001b[A\n",
      "Epoch: 1:  71%|██████████████████████         | 128/180 [00:08<00:03, 16.03it/s]\u001b[A\n",
      "Epoch: 1:  72%|██████████████████████▍        | 130/180 [00:08<00:03, 15.91it/s]\u001b[A\n",
      "Epoch: 1:  73%|██████████████████████▋        | 132/180 [00:08<00:03, 15.73it/s]\u001b[A\n",
      "Epoch: 1:  74%|███████████████████████        | 134/180 [00:08<00:02, 15.53it/s]\u001b[A\n",
      "Epoch: 1:  76%|███████████████████████▍       | 136/180 [00:08<00:02, 15.75it/s]\u001b[A\n",
      "Epoch: 1:  77%|███████████████████████▊       | 138/180 [00:08<00:02, 15.86it/s]\u001b[A\n",
      "Epoch: 1:  78%|████████████████████████       | 140/180 [00:08<00:02, 15.19it/s]\u001b[A\n",
      "Epoch: 1:  79%|████████████████████████▍      | 142/180 [00:08<00:02, 15.41it/s]\u001b[A\n",
      "Epoch: 1:  80%|████████████████████████▊      | 144/180 [00:09<00:02, 15.58it/s]\u001b[A\n",
      "Epoch: 1:  81%|█████████████████████████▏     | 146/180 [00:09<00:02, 15.68it/s]\u001b[A\n",
      "Epoch: 1:  82%|█████████████████████████▍     | 148/180 [00:09<00:01, 16.25it/s]\u001b[A\n",
      "Epoch: 1:  83%|█████████████████████████▊     | 150/180 [00:09<00:01, 16.36it/s]\u001b[A\n",
      "Epoch: 1:  84%|██████████████████████████▏    | 152/180 [00:09<00:01, 16.11it/s]\u001b[A\n",
      "Epoch: 1:  86%|██████████████████████████▌    | 154/180 [00:09<00:01, 15.83it/s]\u001b[A\n",
      "Epoch: 1:  87%|██████████████████████████▊    | 156/180 [00:09<00:01, 15.77it/s]\u001b[A\n",
      "Epoch: 1:  88%|███████████████████████████▏   | 158/180 [00:09<00:01, 15.73it/s]\u001b[A\n",
      "Epoch: 1:  89%|███████████████████████████▌   | 160/180 [00:10<00:01, 15.57it/s]\u001b[A\n",
      "Epoch: 1:  90%|███████████████████████████▉   | 162/180 [00:10<00:01, 15.68it/s]\u001b[A\n",
      "Epoch: 1:  91%|████████████████████████████▏  | 164/180 [00:10<00:01, 15.68it/s]\u001b[A\n",
      "Epoch: 1:  92%|████████████████████████████▌  | 166/180 [00:10<00:00, 15.82it/s]\u001b[A\n",
      "Epoch: 1:  93%|████████████████████████████▉  | 168/180 [00:10<00:00, 15.84it/s]\u001b[A\n",
      "Epoch: 1:  94%|█████████████████████████████▎ | 170/180 [00:10<00:00, 15.99it/s]\u001b[A\n",
      "Epoch: 1:  96%|█████████████████████████████▌ | 172/180 [00:10<00:00, 16.06it/s]\u001b[A\n",
      "Epoch: 1:  97%|█████████████████████████████▉ | 174/180 [00:10<00:00, 15.90it/s]\u001b[A\n",
      "Epoch: 1:  98%|██████████████████████████████▎| 176/180 [00:11<00:00, 15.80it/s]\u001b[A\n",
      "Epoch: 1:  99%|██████████████████████████████▋| 178/180 [00:11<00:00, 15.54it/s]\u001b[A\n",
      "Epoch: 1: 100%|███████████████████████████████| 180/180 [00:11<00:00, 15.42it/s]\u001b[A\n",
      "Epoch: 1: 181it [00:26, 15.42it/s]                                              \u001b[AINFO - model saved in 181 global step at ../data/multitask_data/bert_model/multi_task_model_1_181.pt\n",
      "INFO - \n",
      "Running Evaluation on dev...\n",
      "Eval:   0%|                                              | 0/25 [00:00<?, ?it/s]/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1944: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "Eval: 26it [00:00, 32.08it/s]                                                   \n",
      "INFO - ********** TaskA Evaluation************\n",
      "\n",
      "INFO - classification_accuracy : 59.0\n",
      "INFO - classification_f1_score : 0.37106918238993714\n",
      "INFO - ********** TaskB Evaluation************\n",
      "\n",
      "INFO - classification_accuracy : 37.185929648241206\n",
      "INFO - classification_f1_score : 0.27106227106227104\n",
      "Epoch: 1: 181it [01:17,  2.35it/s]\n",
      "INFO - \n",
      "####################### EPOCH 2 ###################\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 2:   0%|                                         | 0/180 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:   1%|▎                                | 2/180 [00:00<00:10, 16.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:   2%|▋                                | 4/180 [00:00<00:10, 16.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:   3%|█                                | 6/180 [00:00<00:10, 16.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:   4%|█▍                               | 8/180 [00:00<00:10, 16.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:   6%|█▊                              | 10/180 [00:00<00:10, 15.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:   7%|██▏                             | 12/180 [00:00<00:10, 15.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:   8%|██▍                             | 14/180 [00:00<00:10, 15.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:   9%|██▊                             | 16/180 [00:01<00:10, 15.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  10%|███▏                            | 18/180 [00:01<00:10, 15.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  11%|███▌                            | 20/180 [00:01<00:10, 15.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  12%|███▉                            | 22/180 [00:01<00:09, 15.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  13%|████▎                           | 24/180 [00:01<00:09, 15.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  14%|████▌                           | 26/180 [00:01<00:10, 15.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  16%|████▉                           | 28/180 [00:01<00:09, 15.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  17%|█████▎                          | 30/180 [00:01<00:09, 15.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  18%|█████▋                          | 32/180 [00:02<00:09, 15.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  19%|██████                          | 34/180 [00:02<00:09, 15.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  20%|██████▍                         | 36/180 [00:02<00:09, 15.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  21%|██████▊                         | 38/180 [00:02<00:09, 15.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  22%|███████                         | 40/180 [00:02<00:08, 15.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  23%|███████▍                        | 42/180 [00:02<00:08, 15.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  24%|███████▊                        | 44/180 [00:02<00:08, 15.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  26%|████████▏                       | 46/180 [00:02<00:08, 15.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  27%|████████▌                       | 48/180 [00:03<00:08, 15.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  28%|████████▉                       | 50/180 [00:03<00:08, 15.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  29%|█████████▏                      | 52/180 [00:03<00:08, 15.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  30%|█████████▌                      | 54/180 [00:03<00:07, 15.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  31%|█████████▉                      | 56/180 [00:03<00:07, 15.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  32%|██████████▎                     | 58/180 [00:03<00:07, 16.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  33%|██████████▋                     | 60/180 [00:03<00:07, 16.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  34%|███████████                     | 62/180 [00:04<00:10, 11.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  36%|███████████▍                    | 64/180 [00:04<00:09, 12.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  37%|███████████▋                    | 66/180 [00:04<00:08, 13.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  38%|████████████                    | 68/180 [00:04<00:07, 14.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  39%|████████████▍                   | 70/180 [00:04<00:07, 14.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  40%|████████████▊                   | 72/180 [00:04<00:07, 15.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  41%|█████████████▏                  | 74/180 [00:04<00:06, 15.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  42%|█████████████▌                  | 76/180 [00:04<00:06, 15.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  43%|█████████████▊                  | 78/180 [00:05<00:06, 15.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  44%|██████████████▏                 | 80/180 [00:05<00:06, 15.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  46%|██████████████▌                 | 82/180 [00:05<00:06, 15.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  47%|██████████████▉                 | 84/180 [00:05<00:06, 15.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  48%|███████████████▎                | 86/180 [00:05<00:05, 16.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  49%|███████████████▋                | 88/180 [00:05<00:05, 16.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  50%|████████████████                | 90/180 [00:05<00:05, 16.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  51%|████████████████▎               | 92/180 [00:05<00:05, 16.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  52%|████████████████▋               | 94/180 [00:06<00:05, 16.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  53%|█████████████████               | 96/180 [00:06<00:05, 16.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  54%|█████████████████▍              | 98/180 [00:06<00:05, 15.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  56%|█████████████████▏             | 100/180 [00:06<00:05, 15.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  57%|█████████████████▌             | 102/180 [00:06<00:04, 15.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  58%|█████████████████▉             | 104/180 [00:06<00:04, 16.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  59%|██████████████████▎            | 106/180 [00:06<00:04, 16.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  60%|██████████████████▌            | 108/180 [00:06<00:04, 16.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  61%|██████████████████▉            | 110/180 [00:07<00:04, 16.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  62%|███████████████████▎           | 112/180 [00:07<00:04, 15.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  63%|███████████████████▋           | 114/180 [00:07<00:04, 15.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  64%|███████████████████▉           | 116/180 [00:07<00:03, 16.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  66%|████████████████████▎          | 118/180 [00:07<00:03, 16.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  67%|████████████████████▋          | 120/180 [00:07<00:03, 15.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  68%|█████████████████████          | 122/180 [00:07<00:03, 15.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  69%|█████████████████████▎         | 124/180 [00:07<00:03, 15.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  70%|█████████████████████▋         | 126/180 [00:08<00:03, 16.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  71%|██████████████████████         | 128/180 [00:08<00:03, 15.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  72%|██████████████████████▍        | 130/180 [00:08<00:03, 15.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  73%|██████████████████████▋        | 132/180 [00:08<00:03, 15.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  74%|███████████████████████        | 134/180 [00:08<00:02, 15.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  76%|███████████████████████▍       | 136/180 [00:08<00:02, 15.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  77%|███████████████████████▊       | 138/180 [00:08<00:02, 15.76it/s]\u001b[A\u001b[AINFO - Steps: 250 Task: TaskA Avg.Loss: 0.6827939070439596 Task Loss: 0.18743574619293213\n",
      "\n",
      "\n",
      "Epoch: 2:  78%|████████████████████████       | 140/180 [00:09<00:02, 14.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  79%|████████████████████████▍      | 142/180 [00:09<00:02, 15.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  80%|████████████████████████▊      | 144/180 [00:09<00:02, 15.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  81%|█████████████████████████▏     | 146/180 [00:09<00:02, 15.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  82%|█████████████████████████▍     | 148/180 [00:09<00:01, 16.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  83%|█████████████████████████▊     | 150/180 [00:09<00:01, 16.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  84%|██████████████████████████▏    | 152/180 [00:09<00:01, 16.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  86%|██████████████████████████▌    | 154/180 [00:09<00:01, 16.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  87%|██████████████████████████▊    | 156/180 [00:10<00:01, 15.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  88%|███████████████████████████▏   | 158/180 [00:10<00:01, 15.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  89%|███████████████████████████▌   | 160/180 [00:10<00:01, 15.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  90%|███████████████████████████▉   | 162/180 [00:10<00:01, 16.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  91%|████████████████████████████▏  | 164/180 [00:10<00:01, 15.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  92%|████████████████████████████▌  | 166/180 [00:10<00:00, 16.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  93%|████████████████████████████▉  | 168/180 [00:10<00:00, 16.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  94%|█████████████████████████████▎ | 170/180 [00:10<00:00, 16.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  96%|█████████████████████████████▌ | 172/180 [00:10<00:00, 16.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  97%|█████████████████████████████▉ | 174/180 [00:11<00:00, 15.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  98%|██████████████████████████████▎| 176/180 [00:11<00:00, 16.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2:  99%|██████████████████████████████▋| 178/180 [00:11<00:00, 15.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2: 100%|███████████████████████████████| 180/180 [00:11<00:00, 15.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "Epoch: 2: 181it [00:29, 15.98it/s]                                              \u001b[A\u001b[AINFO - model saved in 271 global step at ../data/multitask_data/bert_model/multi_task_model_2_271.pt\n",
      "INFO - \n",
      "Running Evaluation on dev...\n",
      "Eval:   0%|                                              | 0/25 [00:00<?, ?it/s]/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1944: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "Eval: 26it [00:00, 31.66it/s]                                                   \n",
      "INFO - ********** TaskA Evaluation************\n",
      "\n",
      "INFO - classification_accuracy : 59.0\n",
      "INFO - classification_f1_score : 0.37106918238993714\n",
      "INFO - ********** TaskB Evaluation************\n",
      "\n",
      "INFO - classification_accuracy : 62.8140703517588\n",
      "INFO - classification_f1_score : 0.3858024691358025\n",
      "Epoch: 2: 181it [00:44,  4.05it/s]\n"
     ]
    }
   ],
   "source": [
    "! python ../../multi-task-NLP/train.py \\\n",
    "      --data_dir ../data/multitask_data/bert-base-uncased_prepared_data/ \\\n",
    "      --task_file ../data/multitask_data/bert_based_task.yml \\\n",
    "      --learning_rate 5e-3 \\\n",
    "      --out_dir ../data/multitask_data/bert_model/ \\\n",
    "      --epochs 3 \\\n",
    "      --train_batch_size 8 \\\n",
    "      --eval_batch_size 16 \\\n",
    "      --grad_accumulation_steps 2 \\\n",
    "      --max_seq_len 512 \\\n",
    "      --log_per_updates 250 \\\n",
    "      --log_dir ../data/multitask_data/logs/ \\\n",
    "      --limit_save 15\\\n",
    "      --eval_while_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d581ea-72fa-409c-83ff-624637cf7a70",
   "metadata": {},
   "source": [
    "### Train NLI Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f987f0f0-3547-4182-b566-f2fa4b97bd8f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "! python ../../multi-task-NLP/data_preparation.py \\\n",
    "  --task_file ../data/multitask_data/nli_based_task.yml \\\n",
    "  --data_dir ../data/multitask_data/ \\\n",
    "  --max_seq_len 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937dbbf3-cb4d-474e-8a5a-f2fbae19df46",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "! python ../../multi-task-NLP/train.py \\\n",
    "      --data_dir ../data/multitask_data/roberta-large-mnli_prepared_data/ \\\n",
    "      --task_file ../data/multitask_data/nli_based_task.yml \\\n",
    "      --learning_rate 2e-5 \\\n",
    "      --out_dir ../data/multitask_data/nli_model/ \\\n",
    "      --epochs 3 \\\n",
    "      --train_batch_size 8 \\\n",
    "      --eval_batch_size 8 \\\n",
    "      --grad_accumulation_steps 2 \\\n",
    "      --max_seq_len 512 \\\n",
    "      --log_per_updates 100 \\\n",
    "      --log_dir /var/tmp/argsvalidnovel/multitask \\\n",
    "      --limit_save 15\\\n",
    "      --eval_while_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7224c0e2-d161-4568-9d7e-081e082bb763",
   "metadata": {},
   "source": [
    "### Perform prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0d3925-5daa-4a8b-b099-b4271d0c1907",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43357929-faac-4702-ac7a-e3307969203a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import glob\n",
    "import json\n",
    "sys.path.append('../../multi-task-NLP/')\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b604533-9717-42b9-9d06-e466b6d48a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "from infer_pipeline import inferPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a910ace9-1087-4f5d-8eba-529b778f0250",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "bert_model = inferPipeline(modelPath = '../data/multitask_data/bert_model/multi_task_model_10_995.pt', maxSeqLen = 512)\n",
    "nli_model  = inferPipeline(modelPath = '../data/multitask_data/nli_model/multi_task_model_9_905.pt', maxSeqLen = 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf3b156-d28f-47f9-8782-446cd8bb8af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_preds = bert_model.infer(taska_valid_df['input_txt'].tolist(), ['TaskA', 'TaskB']) \n",
    "nli_preds  = nli_model.infer(taska_valid_df['input_txt'].tolist(), ['TaskA', 'TaskB']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db977b5c-06f2-4d64-9de9-6d56890d4d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "taska_valid_df['bert_pred_validity'] = [x['TaskB'][0] for x in bert_preds]\n",
    "taska_valid_df['bert_pred_novelty']  = [x['TaskA'][0] for x in bert_preds]\n",
    "taska_valid_df['nli_pred_validity']  = [x['TaskB'][0] for x in nli_preds]\n",
    "taska_valid_df['nli_pred_novelty']   = [x['TaskA'][0] for x in nli_preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac7ba3e-bba7-4d64-8fb4-3780eeba20f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('BERT Validity: ', f1_score(taska_valid_df.Validity.tolist(), taska_valid_df.bert_pred_validity.tolist(), average='macro'))\n",
    "print('BERT Novelty: ', f1_score(taska_valid_df.Novelty.tolist(), taska_valid_df.bert_pred_novelty.tolist(), average='macro'))\n",
    "\n",
    "print('NLI Validity: ', f1_score(taska_valid_df.Validity.tolist(), taska_valid_df.nli_pred_validity.tolist(), average='macro'))\n",
    "print('NLI Novelty: ', f1_score(taska_valid_df.Novelty.tolist(), taska_valid_df.nli_pred_novelty.tolist(), average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20798a49-0f3d-462b-bbb4-3412f89dc59c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
